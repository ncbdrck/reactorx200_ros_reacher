# YAML Document starts with ---
# Comments start with #
---
  # Training 
  training_steps: 60000      # The number of training steps to perform

  # Save params
  save_freq: 1000000
  save_prefix: dqn_model_real_time_oct26
  trained_model_name: trained_model_real_time_oct26
  save_replay_buffer: False

  # Load model params
  load_model: False
  model_name: dqn_model_5000_steps

  # Logging parameters
  log_folder: DQN_real_time_oct26
  log_interval: 4 # The number of episodes between logs
  reset_num_timesteps: False # If true, will reset the number of timesteps to 0 every training 

  # Use custom policy - Only MlpPolicy is supported (Only used when new model is created)
  use_custom_policy: False
  policy_params:
    net_arch: [400, 300] # List of hidden layer sizes
    activation_fn: relu  # relu, tanh, elu or selu
    features_extractor_class: FlattenExtractor # FlattenExtractor, BaseFeaturesExtractor or CombinedExtractor
    optimizer_class: Adam # Adam, Adadelta, Adagrad, RMSprop or SGD

  # DQN parameters
  dqn_params:
    learning_rate: 0.0001
    buffer_size: 1000000
    learning_starts: 50000 
    batch_size: 32
    tau: 1.0
    gamma: 0.99
    gradient_steps: 1
    target_update_interval: 10000 
    exploration_fraction: 0.1
    exploration_initial_eps: 1.0
    exploration_final_eps: 0.05 
    max_grad_norm: 10
    train_freq:
      freq: 20
      unit: step  # episode or step
    seed: 10